{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e022cb2-ebb7-4a7a-b201-394a7e08dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Ensure your OpenAI API key is set in the environment\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbc279-da55-4355-a58e-d4a55d48505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db475a-a41c-4e85-a9fd-0160c499690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"Categorize the email below into exactly one of the following categories:\n",
    "\n",
    "    Internship — only if it contains an update about the status of my internship applications (e.g., interview invitations, rejections, offers). Application confirmation or acknowledgment emails such as \"Thank you for applying\", \"Thank you for your interest\", \"Thank you for your application\", or \"Your application is under review\" is considered Irrelevant.\n",
    "    \n",
    "    Canvas — only if it announces a grade release for an assignment, quiz, exam, or important information regarding the courses.\n",
    "    \n",
    "    Personal — only if the message is personally written to me and is NOT spam, automated, or promotional.\n",
    "    \n",
    "    Irrelevant — anything else.\n",
    "    \n",
    "    Respond with ONLY the category name.\"\"\"\n",
    "\n",
    "def predict_label(text: str, model: str) -> str:\n",
    "    # make sure text is a plain Python str (not a pandas or numpy object)\n",
    "    text = str(text)\n",
    "    messages = [\n",
    "        {\"role\": \"system\",    \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",      \"content\": text}\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    # inspect the JSON you’ll send\n",
    "    resp = openai.chat.completions.create(**payload)\n",
    "    return resp.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f502cf-38d2-4823-8070-22cac90c0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit testing\n",
    "print(predict_label(df['text'][0], FINE_TUNED_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8a4b8-34a3-49f5-a52a-0b31fdea3500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Batch Predictions\n",
    "FINE_TUNED_MODEL = \"FINE_TUNE_MODEL_NAME\"\n",
    "\n",
    "preds = []\n",
    "for text in df['text']:\n",
    "    preds.append(predict_label(text, FINE_TUNED_MODEL))\n",
    "\n",
    "df['prediction'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51eb12a-0949-4687-a55e-b671f2f11f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'prediction': 'prediction-fine-tune'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc7255-f1c9-40f1-9df7-5ed4938eb77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Metrics\n",
    "acc = accuracy_score(df['label'], df['prediction-fine-tune'])\n",
    "print(f\"Overall Accuracy: {acc:.3f}\\n\")\n",
    "\n",
    "report = classification_report(df['label'], df['prediction-fine-tune'], output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(\"Classification Report:\")\n",
    "report_df\n",
    "\n",
    "# Display confusion matrix\n",
    "labels = [\"Internship\", \"Canvas\", \"Personal\", \"Irrelavent\"]\n",
    "cm = confusion_matrix(df['label'], df['prediction-fine-tune'], labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc584024-76d0-41f9-8b72-1199e3c0802f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test base line performance\n",
    "BASE_MODEL = 'gpt-4o-mini'\n",
    "preds = []\n",
    "for text in df['text']:\n",
    "    preds.append(predict_label(text, BASE_MODEL))\n",
    "\n",
    "df['prediction-baseline'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681fe2f-9904-4e4f-9c77-26e79e4ed5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['prediction-baseline'] == 'Irrelevant', 'prediction-baseline'] = 'Irrelavent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72433a46-b378-49b0-89da-5d6a5763515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics\n",
    "acc_base = accuracy_score(df['label'], df['prediction-baseline'])\n",
    "print(f\"Overall Accuracy: {acc:.3f}\\n\")\n",
    "\n",
    "# Display confusion matrix\n",
    "labels = [\"Internship\", \"Canvas\", \"Personal\", \"Irrelavent\"]\n",
    "cm = confusion_matrix(df['label'], df['prediction-baseline'], labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"\\nConfusion Matrix for base model (4o-mini):\")\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4cdf2-3e56-4824-a020-1215ed9a7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Overall accuracy increase: {((acc - acc_base) / acc_base * 100):.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a9468-5460-42a7-b49e-c75aa25c11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Decrease in misclassified data: {(((23+7) - (2+2)) / (23+7) * 100):.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cbb5a2-499f-45c6-b104-7a245bd422d2",
   "metadata": {},
   "source": [
    "## Conclusions: \n",
    "\n",
    "Fine-tuning is effective as it:\n",
    "- Increased overall accuracy by 16.774%\n",
    "- Decreased misclassified data by 86.667%\n",
    "\n",
    "Also verified my intuition of getting a lot of false Internship updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815cefd4-311b-46f2-b34d-94e7d41178a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
